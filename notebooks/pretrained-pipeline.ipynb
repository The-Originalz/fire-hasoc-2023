{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 15:21:42.025176: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 15:21:56.282021: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 15:21:56.328747: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-19 15:22:33.830255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "curr_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir, '..'))\n",
    "\n",
    "sys.path.append(proj_dir)\n",
    "\n",
    "from src.configuration import load_config\n",
    "\n",
    "def seed_everything(seed=2023):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "cfg = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data and Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NbCfg:\n",
    "    lang = 'assamese'\n",
    "    prefix_lang = 'A'\n",
    "    text_col = 'text'\n",
    "    target_col = 'task_1'\n",
    "    apex = True\n",
    "    model_name = 'bert-base-multilingual-cased'\n",
    "    seed = 42\n",
    "    n_splits = 5\n",
    "    max_len = 256\n",
    "    dropout = 0.3\n",
    "    target_size=2\n",
    "    n_accumulate=1\n",
    "    print_freq = 250\n",
    "    min_lr=1e-7\n",
    "    scheduler = 'cosine'\n",
    "    batch_size = 16\n",
    "    num_workers = 3\n",
    "    lr = 5e-5\n",
    "    weigth_decay = 0.02\n",
    "    epochs = 5\n",
    "    train = True \n",
    "    num_warmup_steps = 0\n",
    "    num_cycles=0.5\n",
    "    debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(cfg['data']['inp'], f'{NbCfg.lang}/train_{NbCfg.prefix_lang}_AH_HASOC2023.csv'))\n",
    "test_df = pd.read_csv(os.path.join(cfg['data']['inp'], f'{NbCfg.lang}/test_{NbCfg.prefix_lang}_AH_HASOC2023.csv'))\n",
    "sub_df = pd.read_csv(os.path.join(cfg['data']['inp'], f'{NbCfg.lang}/sample.csv'))\n",
    "\n",
    "if NbCfg.debug:\n",
    "    train_df = train_df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert target to labels\n",
    "tar2num = {'HOF': 0, 'NOT': 1}\n",
    "num2tar = {0: 'HOF', 1: 'NOT'}\n",
    "\n",
    "train_df[NbCfg.target_col] = train_df[NbCfg.target_col].map(tar2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(NbCfg.model_name, from_pt=True)\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasocDataLoader(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length, is_train=True):\n",
    "        self.df = df\n",
    "        self.max_len = max_length\n",
    "        self.text = df[NbCfg.text_col].values\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_train = is_train\n",
    "        if is_train:\n",
    "            self.targets = df[NbCfg.target_col].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length = self.max_len\n",
    "        )\n",
    "        return {\n",
    "            'input_ids':inputs['input_ids'],\n",
    "            'attention_mask':inputs['attention_mask'],\n",
    "            'target':self.targets[index]\n",
    "            } if self.is_train else {\n",
    "            'input_ids':inputs['input_ids'],\n",
    "            'attention_mask':inputs['attention_mask'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "================================================================================ FOLD: 0 ================================================================================\n",
      "\n",
      "\n",
      "================================================================================ FOLD: 1 ================================================================================\n",
      "\n",
      "\n",
      "================================================================================ FOLD: 2 ================================================================================\n",
      "\n",
      "\n",
      "================================================================================ FOLD: 3 ================================================================================\n",
      "\n",
      "\n",
      "================================================================================ FOLD: 4 ================================================================================\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df[NbCfg.target_col])):\n",
    "    print('\\n')\n",
    "    print(80*'=', f'FOLD: {fold}', 80*'=')\n",
    "\n",
    "    trn_df = train_df.iloc[train_idx]\n",
    "    val_df = train_df.iloc[val_idx]\n",
    "\n",
    "    train_ds = HasocDataLoader(train_df, tokenizer, NbCfg.max_len)\n",
    "    val_ds = HasocDataLoader(val_df, tokenizer, NbCfg.max_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hasoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
