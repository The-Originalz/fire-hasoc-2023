{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 12:44:25.626979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 12:44:33.983418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-19 12:44:34.034584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-19 12:45:04.594065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'inp': './../inp', 'out': './../out'}, 'logs': './../logs', 'hyps': {'n_split': 5, 'max_len': {'assamese': 256}, 'random_state': [42, 2023]}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.layers as L\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import pad_sequences\n",
    "from keras.layers import Layer, Dropout, Dense, Input, Embedding, Bidirectional, LSTM, Concatenate\n",
    "\n",
    "curr_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir, '..'))\n",
    "\n",
    "sys.path.append(proj_dir)\n",
    "\n",
    "from src.configuration import load_config\n",
    "\n",
    "def seed_everything(seed=2023):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything()\n",
    "\n",
    "cfg = load_config()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(cfg['data']['inp'], 'assamese/train_A_AH_HASOC2023.csv'))\n",
    "test_df = pd.read_csv(os.path.join(cfg['data']['inp'], 'assamese/test_A_AH_HASOC2023.csv'))\n",
    "sub_df = pd.read_csv(os.path.join(cfg['data']['inp'], 'assamese/sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 256\n",
    "VOCAB_SIZE = 20000\n",
    "EMBED_DIM = 128\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 5\n",
    "CLASSES = 2\n",
    "\n",
    "TEXT_COL = \"text\"\n",
    "TARGET_COL = \"task_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train:  4036\n",
      "Length of test:  1009\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of train: \", len(train_df))\n",
    "print(\"Length of test: \", len(test_df))\n",
    "\n",
    "tar2num = {'HOF' : 0, 'NOT' : 1}\n",
    "num2tar = {0 : 'HOF', 1 : 'NOT'}\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, filters='!\"#$&(),.:;?@[\\\\]^_`{|}\\t\\n')\n",
    "tokenizer.fit_on_texts(list(train_df[TEXT_COL]) + list(test_df[TEXT_COL]))\n",
    "word_idx = tokenizer.word_index\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(list(train_df[TEXT_COL]))\n",
    "y_train = train_df[TARGET_COL].map(tar2num)\n",
    "\n",
    "X_test = tokenizer.texts_to_sequences(list(test_df[TEXT_COL]))\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=MAXLEN)\n",
    "X_test = pad_sequences(X_test, maxlen=MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(keras.Model):\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W1 = Dense(units=units)\n",
    "        self.W2 = Dense(units=units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, features, hidden):\n",
    "        hidden_t = K.expand_dims(hidden, 1)\n",
    "        # additive attention\n",
    "        score = K.tanh(self.W1(features) + self.W2(hidden_t))\n",
    "\n",
    "        attn_weights = K.softmax(self.V(score), axis=1)\n",
    "\n",
    "        context = attn_weights * features\n",
    "        context = tf.reduce_sum(context, axis=1)\n",
    "\n",
    "        return context, attn_weights\n",
    "        pass\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_model(max_len, max_features, embed_size, attn_units=20, num_classes=4, rnn_cell_size=32):\n",
    "    seq_inp = Input(shape=max_len, dtype=\"int32\")\n",
    "    embedded_seq = Embedding(max_features, embed_size)(seq_inp)\n",
    "    lstm = Bidirectional(LSTM(\n",
    "        rnn_cell_size, return_sequences=True\n",
    "    ), name=\"bilstm_0\")(embedded_seq)\n",
    "\n",
    "    lstm, f_h, f_c, b_h, b_c = Bidirectional(LSTM(\n",
    "        rnn_cell_size, return_sequences=True, return_state=True\n",
    "    ), name=\"bilstm_1\")(lstm)\n",
    "\n",
    "    h_ = Concatenate()([f_h, b_h])\n",
    "    c_ = Concatenate()([f_c, b_c])\n",
    "\n",
    "    context, attn_weights = AttentionBlock(attn_units)(lstm, h_)\n",
    "\n",
    "    fc_pre = Dense(num_classes * 4, activation=\"relu\")(context)\n",
    "    do = Dropout(0.05)(fc_pre)\n",
    "    output = Dense(1, activation=\"sigmoid\")(do)\n",
    "\n",
    "    return keras.Model(inputs=seq_inp, outputs=output)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-19 12:46:15.226977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-19 12:46:15.693371: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 256)]                0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 256, 128)             2560000   ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " bilstm_0 (Bidirectional)    (None, 256, 64)              41216     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " bilstm_1 (Bidirectional)    [(None, 256, 64),            24832     ['bilstm_0[0][0]']            \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32),                                                         \n",
      "                              (None, 32)]                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64)                   0         ['bilstm_1[0][1]',            \n",
      "                                                                     'bilstm_1[0][3]']            \n",
      "                                                                                                  \n",
      " attention_block (Attention  ((None, 64),                 2621      ['bilstm_1[0][0]',            \n",
      " Block)                       (None, 256, 1))                        'concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 8)                    520       ['attention_block[0][0]']     \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 8)                    0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    9         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2629198 (10.03 MB)\n",
      "Trainable params: 2629198 (10.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(max_len=MAXLEN, max_features=VOCAB_SIZE, embed_size=EMBED_DIM, num_classes=CLASSES)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "             optimizer=\"adam\",\n",
    "             metrics=[tf.keras.metrics.binary_crossentropy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======FOLD 0=====\n",
      "\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 25s 642ms/step - loss: 0.6817 - binary_crossentropy: 0.6817 - val_loss: 0.6802 - val_binary_crossentropy: 0.6802\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 15s 573ms/step - loss: 0.6801 - binary_crossentropy: 0.6801 - val_loss: 0.6796 - val_binary_crossentropy: 0.6796\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 15s 584ms/step - loss: 0.6767 - binary_crossentropy: 0.6767 - val_loss: 0.6740 - val_binary_crossentropy: 0.6740\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 15s 570ms/step - loss: 0.5046 - binary_crossentropy: 0.5046 - val_loss: 0.7524 - val_binary_crossentropy: 0.7524\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 15s 575ms/step - loss: 0.2130 - binary_crossentropy: 0.2130 - val_loss: 0.9301 - val_binary_crossentropy: 0.9301\n",
      "26/26 [==============================] - 3s 83ms/step\n",
      "32/32 [==============================] - 3s 82ms/step\n",
      "\n",
      "======FOLD 1=====\n",
      "\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 16s 584ms/step - loss: 0.3262 - binary_crossentropy: 0.3262 - val_loss: 0.1421 - val_binary_crossentropy: 0.1421\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 15s 578ms/step - loss: 0.1811 - binary_crossentropy: 0.1811 - val_loss: 0.1345 - val_binary_crossentropy: 0.1345\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 15s 568ms/step - loss: 0.1195 - binary_crossentropy: 0.1195 - val_loss: 0.1688 - val_binary_crossentropy: 0.1688\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 15s 591ms/step - loss: 0.0951 - binary_crossentropy: 0.0951 - val_loss: 0.1869 - val_binary_crossentropy: 0.1869\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 15s 575ms/step - loss: 0.0812 - binary_crossentropy: 0.0812 - val_loss: 0.2061 - val_binary_crossentropy: 0.2061\n",
      "26/26 [==============================] - 3s 89ms/step\n",
      "32/32 [==============================] - 3s 85ms/step\n",
      "\n",
      "======FOLD 2=====\n",
      "\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 16s 580ms/step - loss: 0.1034 - binary_crossentropy: 0.1034 - val_loss: 0.0577 - val_binary_crossentropy: 0.0577\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 15s 591ms/step - loss: 0.0691 - binary_crossentropy: 0.0691 - val_loss: 0.0558 - val_binary_crossentropy: 0.0558\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 14s 558ms/step - loss: 0.0579 - binary_crossentropy: 0.0579 - val_loss: 0.0878 - val_binary_crossentropy: 0.0878\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 15s 567ms/step - loss: 0.0525 - binary_crossentropy: 0.0525 - val_loss: 0.0714 - val_binary_crossentropy: 0.0714\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 15s 568ms/step - loss: 0.0482 - binary_crossentropy: 0.0482 - val_loss: 0.0803 - val_binary_crossentropy: 0.0803\n",
      "26/26 [==============================] - 3s 89ms/step\n",
      "32/32 [==============================] - 3s 88ms/step\n",
      "\n",
      "======FOLD 3=====\n",
      "\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 17s 589ms/step - loss: 0.0536 - binary_crossentropy: 0.0536 - val_loss: 0.0417 - val_binary_crossentropy: 0.0417\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 15s 572ms/step - loss: 0.0494 - binary_crossentropy: 0.0494 - val_loss: 0.0570 - val_binary_crossentropy: 0.0570\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 15s 565ms/step - loss: 0.0393 - binary_crossentropy: 0.0393 - val_loss: 0.0756 - val_binary_crossentropy: 0.0756\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 15s 574ms/step - loss: 0.0361 - binary_crossentropy: 0.0361 - val_loss: 0.0613 - val_binary_crossentropy: 0.0613\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 15s 584ms/step - loss: 0.0278 - binary_crossentropy: 0.0278 - val_loss: 0.0712 - val_binary_crossentropy: 0.0712\n",
      "26/26 [==============================] - 3s 90ms/step\n",
      "32/32 [==============================] - 3s 88ms/step\n",
      "\n",
      "======FOLD 4=====\n",
      "\n",
      "Epoch 1/5\n",
      "26/26 [==============================] - 17s 604ms/step - loss: 0.0429 - binary_crossentropy: 0.0429 - val_loss: 0.0142 - val_binary_crossentropy: 0.0142\n",
      "Epoch 2/5\n",
      "26/26 [==============================] - 15s 570ms/step - loss: 0.0348 - binary_crossentropy: 0.0348 - val_loss: 0.0146 - val_binary_crossentropy: 0.0146\n",
      "Epoch 3/5\n",
      "26/26 [==============================] - 15s 570ms/step - loss: 0.0309 - binary_crossentropy: 0.0309 - val_loss: 0.0229 - val_binary_crossentropy: 0.0229\n",
      "Epoch 4/5\n",
      "26/26 [==============================] - 15s 564ms/step - loss: 0.0318 - binary_crossentropy: 0.0318 - val_loss: 0.0239 - val_binary_crossentropy: 0.0239\n",
      "Epoch 5/5\n",
      "26/26 [==============================] - 17s 673ms/step - loss: 0.0261 - binary_crossentropy: 0.0261 - val_loss: 0.0212 - val_binary_crossentropy: 0.0212\n",
      "26/26 [==============================] - 3s 93ms/step\n",
      "32/32 [==============================] - 3s 87ms/step\n"
     ]
    }
   ],
   "source": [
    "cv_splits = list(StratifiedKFold(n_splits=5).split(X_train, y_train))\n",
    "\n",
    "oof_preds = np.zeros((X_train.shape[0],))\n",
    "test_preds = np.zeros((X_test.shape[0],))\n",
    "\n",
    "for fold in range(5):\n",
    "    K.clear_session()\n",
    "    train_idx, val_idx = cv_splits[fold]\n",
    "    print(\"\\n======FOLD {}=====\".format(fold))\n",
    "    print()\n",
    "    model.fit(X_train[train_idx], y_train[train_idx],\n",
    "                batch_size=BATCH_SIZE,\n",
    "                epochs=EPOCHS,\n",
    "                validation_data=(X_train[val_idx], y_train[val_idx]))\n",
    "\n",
    "    oof_preds[val_idx] += model.predict(X_train[val_idx])[:, 0]\n",
    "    test_preds += model.predict(X_test)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Finished...\n",
      "Performance in training Data...\n",
      "F1 Score for Training:  0.9079356826428233\n",
      "Classification report for training: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      2347\n",
      "           1       0.88      0.91      0.89      1689\n",
      "\n",
      "    accuracy                           0.91      4036\n",
      "   macro avg       0.91      0.91      0.91      4036\n",
      "weighted avg       0.91      0.91      0.91      4036\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Finished...\")\n",
    "print(\"Performance in training Data...\")\n",
    "oof_pred = tf.math.greater_equal(oof_preds, 0.5)\n",
    "val_f1_score = f1_score(y_true=y_train, y_pred=oof_pred, average='macro')\n",
    "print(\"F1 Score for Training: \", val_f1_score)\n",
    "print(\"Classification report for training: \\n\", classification_report(y_true=y_train, y_pred=oof_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test data...\n"
     ]
    }
   ],
   "source": [
    "y_preds = test_preds / 5\n",
    "\n",
    "print(\"Evaluation on test data...\")\n",
    "y_pred = tf.math.greater_equal(y_preds, 0.5).numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task_1\n",
       "HOF    589\n",
       "NOT    420\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['task_1'] = y_pred\n",
    "test_df['task_1'] = test_df['task_1'].map(num2tar)\n",
    "test_df['task_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['S. No.', 'task_1']].to_csv(f'./../out/baseline_lstm_submission_{val_f1_score}localF1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hasoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
